{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import GeonamesDataset\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geonames = GeonamesDataset(\"./data/cities500.txt.gz\", max_len=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sequence</th><th>feature code</th><th>country code</th><th>population</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Peaugres&quot;</td><td>&quot;PPL&quot;</td><td>&quot;FR&quot;</td><td>1785</td></tr><tr><td>&quot;Glenshaw&quot;</td><td>&quot;PPL&quot;</td><td>&quot;US&quot;</td><td>8981</td></tr><tr><td>&quot;Harahan&quot;</td><td>&quot;PPL&quot;</td><td>&quot;US&quot;</td><td>9350</td></tr><tr><td>&quot;Oberursel&quot;</td><td>&quot;PPL&quot;</td><td>&quot;DE&quot;</td><td>46678</td></tr><tr><td>&quot;Kannod&quot;</td><td>&quot;PPL&quot;</td><td>&quot;IN&quot;</td><td>15870</td></tr><tr><td>&quot;Issiglio&quot;</td><td>&quot;PPLA3&quot;</td><td>&quot;IT&quot;</td><td>337</td></tr><tr><td>&quot;Laucha&quot;</td><td>&quot;PPL&quot;</td><td>&quot;DE&quot;</td><td>2517</td></tr><tr><td>&quot;Xiadong&quot;</td><td>&quot;PPLA4&quot;</td><td>&quot;CN&quot;</td><td>0</td></tr><tr><td>&quot;Bangunmulyo&quot;</td><td>&quot;PPLA4&quot;</td><td>&quot;ID&quot;</td><td>0</td></tr><tr><td>&quot;Begbessou&quot;</td><td>&quot;PPL&quot;</td><td>&quot;CI&quot;</td><td>6463</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌─────────────┬──────────────┬──────────────┬────────────┐\n",
       "│ sequence    ┆ feature code ┆ country code ┆ population │\n",
       "│ ---         ┆ ---          ┆ ---          ┆ ---        │\n",
       "│ str         ┆ str          ┆ str          ┆ i64        │\n",
       "╞═════════════╪══════════════╪══════════════╪════════════╡\n",
       "│ Peaugres    ┆ PPL          ┆ FR           ┆ 1785       │\n",
       "│ Glenshaw    ┆ PPL          ┆ US           ┆ 8981       │\n",
       "│ Harahan     ┆ PPL          ┆ US           ┆ 9350       │\n",
       "│ Oberursel   ┆ PPL          ┆ DE           ┆ 46678      │\n",
       "│ Kannod      ┆ PPL          ┆ IN           ┆ 15870      │\n",
       "│ Issiglio    ┆ PPLA3        ┆ IT           ┆ 337        │\n",
       "│ Laucha      ┆ PPL          ┆ DE           ┆ 2517       │\n",
       "│ Xiadong     ┆ PPLA4        ┆ CN           ┆ 0          │\n",
       "│ Bangunmulyo ┆ PPLA4        ┆ ID           ┆ 0          │\n",
       "│ Begbessou   ┆ PPL          ┆ CI           ┆ 6463       │\n",
       "└─────────────┴──────────────┴──────────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geonames.df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = geonames.df\n",
    "alphabet = \"\".join(\n",
    "    set(\"\".join(df.get_column(\"sequence\").str.split(\"\").explode().to_list()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Tokenizer\n",
    "\n",
    "t = Tokenizer(\n",
    "    alphabet=alphabet,\n",
    "    max_len=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t.encode(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: torch.Size([101200, 16])\n",
      "Test set size: torch.Size([12650, 16])\n",
      "Validation set size: torch.Size([12651, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "total_samples = X.size(0)\n",
    "\n",
    "# Define the proportions for train, test, and validation sets\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Calculate the number of samples for each set\n",
    "num_train = int(total_samples * train_ratio)\n",
    "num_test = int(total_samples * test_ratio)\n",
    "num_val = total_samples - num_train - num_test\n",
    "\n",
    "# Generate random indices\n",
    "indices = torch.randperm(total_samples)\n",
    "\n",
    "# Split the indices into train, test, and validation sets\n",
    "train_indices = indices[:num_train]\n",
    "test_indices = indices[num_train : num_train + num_test]\n",
    "val_indices = indices[num_train + num_test :]\n",
    "\n",
    "# Create the train, test, and validation sets\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "X_val = X[val_indices]\n",
    "\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "print(\"Validation set size:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train = TensorDataset(X_train)\n",
    "test = TensorDataset(X_test)\n",
    "val = TensorDataset(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch_ in enumerate(DataLoader(train, batch_size=64)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_T = 1000\n",
    "d_embed = 128\n",
    "token_dim = n_tokens = len(t.stoi)\n",
    "d_kq = 5\n",
    "d_postembed = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import ForwardDiffusionProcess, Scheduler\n",
    "\n",
    "from model import TokenDenoiser\n",
    "\n",
    "scheduler = Scheduler(T=max_T)\n",
    "diffusion = ForwardDiffusionProcess(scheduler=scheduler)\n",
    "model = TokenDenoiser(\n",
    "    max_T=max_T,\n",
    "    max_L=token_dim,\n",
    "    d_embed=d_embed,\n",
    "    d_kq=d_kq,\n",
    "    d_hidden=64,\n",
    "    n_blocks=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bd956fe4e943dd84f89c228a25ac57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(x_0_pred, x_0)\n\u001b[1;32m     34\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/github/toponym_diffusion/.venv/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/toponym_diffusion/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/toponym_diffusion/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "batch_size = 1024\n",
    "num_epochs = 10\n",
    "optimizer = AdamW(model.parameters(), lr=0.1)\n",
    "\n",
    "scheduler = lr_scheduler.ExponentialLR(\n",
    "    optimizer,\n",
    "    gamma=0.99,\n",
    ")\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # get into training mode\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch_num in range(X_train.shape[0] // batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # initialize proper `x`\n",
    "        ix = torch.randint(0, X_train.shape[0], size=(batch_size,))\n",
    "        batch = X_train[ix].long()\n",
    "\n",
    "        # encode into probas\n",
    "        x_0 = F.one_hot(batch, num_classes=n_tokens).float()\n",
    "        time = torch.randint(low=0, high=max_T, size=(x_0.shape[0],))\n",
    "\n",
    "        x_t = diffusion.sample_T(x_0, time)\n",
    "        x_0_pred = model(batch, time)\n",
    "\n",
    "        loss = F.cross_entropy(x_0_pred, x_0)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # validation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        time = torch.randint(0, max_T, size=(X_test.shape[0],))\n",
    "        batch_test = X_test.long()\n",
    "\n",
    "        x_0_test = F.one_hot(batch_test, num_classes=n_tokens).float()\n",
    "        x_t_test = diffusion.sample_T(x_0_test, time)\n",
    "        x_0_test_pred = model(batch_test, time)\n",
    "        test_loss = F.cross_entropy(x_0_test_pred, x_0_test)\n",
    "\n",
    "        print(\n",
    "            f\"{epoch=}, train_loss={torch.tensor(losses).mean().item():2.4f}, val_loss={test_loss.item():2.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 5.0730e-01, -1.7665e-01,  1.0395e+00,  7.0814e-01,  6.5620e-01],\n",
      "        [ 7.7636e-01,  7.6715e-01,  1.2322e+00, -4.3079e-01,  1.5114e+00],\n",
      "        [ 2.6183e-01,  5.2399e-01, -3.5735e-03,  1.8499e-01,  6.7456e-01],\n",
      "        [ 6.7750e-01,  1.0152e-01,  9.9663e-01,  4.1857e-01, -5.7225e-02],\n",
      "        [-6.1855e-02,  1.4560e-01,  4.3867e-01,  2.9079e-01,  3.2104e-01],\n",
      "        [ 7.7865e-01,  7.9962e-01,  1.3476e+00, -3.8759e-01,  1.2185e+00],\n",
      "        [ 4.5905e-01, -1.0935e-01,  9.3626e-02,  4.8394e-01, -1.7012e-01],\n",
      "        [ 1.4235e+00,  3.3231e-01,  1.3097e+00, -6.5856e-04,  1.5425e+00],\n",
      "        [ 5.9915e-01,  1.0745e+00,  7.3774e-01, -7.7221e-02,  1.1816e+00],\n",
      "        [ 1.3653e+00,  7.1614e-01,  4.7300e-01,  2.3979e-01,  5.5055e-01],\n",
      "        [-5.4933e-02, -4.6900e-01, -3.9010e-01,  5.4395e-01,  1.1521e-01],\n",
      "        [ 3.6646e-01,  6.2784e-01,  5.7957e-01, -1.3852e-01,  7.4064e-01],\n",
      "        [ 8.8656e-01, -2.6590e-02,  1.2515e-01,  9.4088e-01,  1.7703e-01],\n",
      "        [ 1.1372e+00,  6.7863e-01,  1.4445e+00, -1.9439e-01,  1.2830e+00],\n",
      "        [ 1.8681e-01,  3.1810e-02, -4.9227e-01,  1.0725e+00,  2.4047e-01],\n",
      "        [ 5.1394e-01,  6.1465e-03,  3.2423e-01,  7.6738e-01,  3.9560e-01],\n",
      "        [ 3.5665e-01,  7.4839e-01,  4.4048e-01, -2.4661e-01,  1.1242e+00],\n",
      "        [-5.3237e-02, -2.5460e-01,  5.5350e-01,  7.3700e-01, -4.1284e-02],\n",
      "        [ 3.2402e-01,  8.2459e-01,  5.6870e-01,  5.8594e-01,  6.3236e-01],\n",
      "        [ 8.1860e-01,  7.1546e-01,  1.4377e+00,  3.9652e-01,  1.4360e+00],\n",
      "        [-2.6843e-02,  1.5317e-01,  4.6838e-01,  1.0294e+00,  1.3364e-01],\n",
      "        [ 1.2255e+00,  6.1055e-01,  7.1412e-01,  1.7454e-01,  1.1484e+00],\n",
      "        [ 7.0401e-01,  1.4790e-01,  2.2303e-01,  2.0921e-01,  4.3022e-01],\n",
      "        [ 1.3405e+00,  3.5846e-01,  1.2742e+00, -1.5342e-01,  9.1126e-01],\n",
      "        [ 1.6320e-01, -1.4495e-01,  4.4751e-01,  6.9332e-01,  1.2816e-01],\n",
      "        [ 4.6611e-01,  5.8543e-01,  7.1592e-01, -1.4944e-01,  8.7634e-01],\n",
      "        [ 5.2030e-01, -3.7219e-01,  5.2783e-01,  2.9620e-01,  2.6394e-01],\n",
      "        [ 1.1360e+00,  7.3277e-01,  7.7301e-01, -3.7491e-01,  7.8898e-01],\n",
      "        [ 2.9941e-01, -2.8745e-01,  2.8247e-01,  8.1297e-01, -1.5999e-01],\n",
      "        [ 2.1161e-01, -1.7687e-01, -1.4171e-01,  1.1234e+00,  4.3286e-02],\n",
      "        [ 3.8182e-01,  7.2268e-01,  2.8721e-01,  9.6905e-01,  5.5169e-01],\n",
      "        [ 1.3671e-01, -5.8904e-02,  7.5310e-01,  1.0542e+00,  1.5086e-01],\n",
      "        [ 1.0388e+00,  1.0636e+00,  1.1415e+00, -3.0330e-01,  1.0947e+00],\n",
      "        [ 2.7561e-01,  4.7343e-01,  7.9244e-01,  8.2941e-01,  3.9968e-01],\n",
      "        [ 1.5099e+00,  6.4673e-01,  1.3556e+00, -1.5358e-01,  1.3809e+00],\n",
      "        [ 1.4359e-02, -3.3961e-01, -5.8205e-04,  2.3259e-01,  4.8262e-01],\n",
      "        [ 8.2516e-01,  1.0245e+00,  3.8711e-01,  3.9628e-01,  8.9503e-01],\n",
      "        [ 1.5063e+00,  4.9280e-01,  1.4382e+00, -1.2652e-01,  8.2623e-01],\n",
      "        [ 5.7872e-01,  6.2494e-01,  1.0375e+00,  6.7902e-01,  5.4013e-01],\n",
      "        [ 1.4064e+00,  7.7179e-01,  1.3211e+00, -1.6178e-01,  1.1868e+00],\n",
      "        [ 5.2674e-01,  2.0467e-01,  2.1255e-01,  7.4518e-01,  1.6292e-01],\n",
      "        [ 9.2802e-01,  2.7121e-01,  1.4023e+00, -5.7617e-01,  1.4046e+00],\n",
      "        [ 3.7558e-01,  3.2709e-01,  7.9293e-01,  7.6563e-01,  1.7987e-01],\n",
      "        [ 1.6202e+00,  1.2183e+00,  1.3556e+00,  2.7169e-01,  1.1120e+00],\n",
      "        [-4.6408e-01, -1.2802e-01, -1.5972e-01,  1.4806e+00, -7.8653e-02],\n",
      "        [ 1.4908e+00,  8.6952e-01,  1.3553e+00, -2.3100e-01,  7.1877e-01],\n",
      "        [-7.0869e-02, -2.7835e-01, -3.6820e-01,  8.5709e-01,  1.0043e-02],\n",
      "        [ 1.3834e+00,  8.3703e-01,  1.2272e+00,  6.4533e-02,  1.1170e+00],\n",
      "        [ 3.7965e-01, -5.7458e-01, -4.8713e-01,  7.5833e-01, -4.1669e-01],\n",
      "        [ 9.9073e-01,  7.6520e-01,  8.4123e-01,  2.8467e-01,  5.0038e-01],\n",
      "        [-2.6709e-01, -3.2637e-02, -2.6063e-01,  9.3263e-01, -2.2546e-01],\n",
      "        [ 8.1565e-01,  5.2805e-01,  8.4524e-01,  1.8783e-01,  4.2633e-01],\n",
      "        [ 1.1931e-03,  1.6427e-01, -3.0639e-01,  1.3594e+00, -3.6066e-01],\n",
      "        [ 7.8545e-01,  2.8109e-01,  9.2154e-01,  9.8415e-02,  9.3281e-01],\n",
      "        [-4.3715e-01, -9.1324e-02,  2.5251e-02,  1.1141e+00, -1.0774e-01],\n",
      "        [ 8.5993e-01,  1.4480e-01,  1.1277e+00,  3.8660e-01,  1.1117e+00],\n",
      "        [-1.0306e-01, -2.7134e-01, -6.3485e-02,  1.2787e+00,  2.6142e-01],\n",
      "        [ 3.3969e-01,  1.9263e-01, -2.0146e-01,  4.0560e-01,  5.4534e-01],\n",
      "        [-4.5124e-01, -1.3042e-01, -2.7221e-01,  1.0984e+00,  6.8117e-02],\n",
      "        [ 3.1826e-01, -2.0021e-01,  2.8164e-01,  4.2630e-01, -5.0516e-02],\n",
      "        [ 5.9475e-02, -3.2969e-01, -5.3496e-01,  1.3614e+00,  7.2675e-02],\n",
      "        [ 8.2761e-01,  5.2549e-01,  2.7978e-01,  4.5847e-01,  1.0504e+00],\n",
      "        [-6.0268e-01, -4.5111e-01,  1.5579e-01,  8.4717e-01,  8.5562e-03],\n",
      "        [ 9.0588e-01, -1.1716e-01,  2.6176e-01,  6.4966e-01,  8.1635e-01],\n",
      "        [-2.4842e-01, -5.7933e-01, -5.1409e-01,  4.9578e-01,  2.8259e-01],\n",
      "        [ 1.3165e-01,  1.8512e-01, -1.5384e-01,  9.0653e-01,  2.8281e-01],\n",
      "        [-2.3233e-01, -5.1799e-01, -1.9325e-01,  8.0517e-01,  1.4878e-01],\n",
      "        [ 3.5248e-01, -4.0135e-01,  2.4798e-01,  1.0025e+00,  1.7445e-01],\n",
      "        [-3.9904e-01,  5.0842e-01, -1.7701e-01,  6.9319e-01, -3.9809e-01],\n",
      "        [ 7.2191e-01,  4.4148e-01,  8.5099e-01,  2.7043e-01,  8.0891e-02],\n",
      "        [ 6.1708e-01,  5.8391e-01,  6.1845e-01,  6.5220e-01,  2.5646e-01],\n",
      "        [ 1.9706e-01,  3.0118e-01,  5.0290e-01,  5.9921e-01,  6.5136e-01],\n",
      "        [ 6.2346e-01, -1.4403e-01,  1.4140e-01,  1.3731e+00,  3.4029e-01],\n",
      "        [ 1.0536e+00,  5.7391e-01,  7.2855e-01,  5.6969e-01,  5.1049e-01],\n",
      "        [ 4.2198e-01,  6.0273e-01,  5.5116e-01,  7.0981e-01,  6.1830e-02],\n",
      "        [ 2.0538e-01,  1.5165e-01,  1.8367e-01,  1.1673e+00,  4.6704e-01],\n",
      "        [ 2.4510e-01,  2.7896e-01,  2.1001e-01,  1.2983e+00, -1.2939e-01],\n",
      "        [ 2.6672e-01,  3.1482e-01, -1.4560e-01,  3.9869e-01,  1.0182e-01],\n",
      "        [-3.2105e-01, -4.9948e-01,  3.4933e-01,  4.5229e-01,  1.6466e-01],\n",
      "        [ 3.2488e-01, -4.3941e-01,  2.1736e-01,  7.1594e-01,  4.0849e-01],\n",
      "        [ 3.3988e-01,  2.8452e-01,  4.1684e-01,  5.2422e-01,  1.3661e-01],\n",
      "        [ 1.2306e-01,  8.0558e-03,  3.2375e-01,  7.0824e-01, -2.8339e-02],\n",
      "        [ 4.3666e-02, -2.4194e-01,  1.0492e-01,  5.0047e-01,  7.0656e-02],\n",
      "        [-3.0215e-01,  3.4542e-01, -6.5164e-02,  4.7708e-01,  2.9241e-02],\n",
      "        [ 1.9075e-01,  1.4423e-01,  1.1908e-01,  8.4960e-01, -4.1316e-01],\n",
      "        [ 6.5512e-02, -6.2653e-02,  5.0286e-01,  8.9873e-01, -4.2555e-01],\n",
      "        [ 5.0398e-01, -3.9926e-01,  5.9864e-02,  1.0689e+00,  2.7550e-01],\n",
      "        [-8.4132e-02,  2.5388e-01,  5.5232e-01,  5.2149e-01, -1.8702e-01],\n",
      "        [ 4.5195e-01, -2.0286e-01,  5.8587e-02,  4.5263e-01, -1.0933e-01],\n",
      "        [ 5.4840e-01, -5.7029e-01, -2.9249e-02,  9.8950e-01,  4.1784e-01],\n",
      "        [-1.0147e-01, -2.4649e-01, -6.9512e-02,  6.5177e-01,  1.2096e-01],\n",
      "        [ 4.9630e-01,  2.5900e-01, -2.8082e-01,  1.1078e+00,  3.0562e-01],\n",
      "        [-1.0885e-01,  1.0071e-01,  1.1908e-01,  4.8567e-01, -2.0536e-01],\n",
      "        [ 6.2990e-01, -3.5125e-01,  1.3694e-01,  8.6167e-01,  3.1538e-01],\n",
      "        [-1.7514e-02, -1.4832e-01,  1.8979e-01,  1.0978e+00,  1.3993e-01],\n",
      "        [ 1.6731e-01, -1.4947e-01,  5.7282e-02,  1.0729e+00, -2.5727e-01],\n",
      "        [ 3.0630e-01, -4.7808e-01,  5.1279e-02,  9.0500e-01,  1.1223e-01],\n",
      "        [ 5.3620e-01, -2.6273e-01,  3.8664e-02,  1.1401e+00,  4.3238e-02],\n",
      "        [ 1.7083e-01, -5.6108e-01, -3.1435e-01,  6.1461e-01, -1.9286e-01],\n",
      "        [ 1.9184e-01,  2.9689e-01,  6.2949e-01,  8.8588e-01,  1.2427e-01],\n",
      "        [-1.5569e-01, -4.7145e-01,  6.1161e-01,  1.0875e+00,  1.9839e-01],\n",
      "        [ 4.2966e-01,  2.8957e-01, -3.1747e-01,  5.3221e-01, -1.4356e-01],\n",
      "        [ 3.7493e-01,  2.3576e-01,  4.1986e-01,  8.3801e-01,  4.6967e-01],\n",
      "        [ 1.4759e-01, -2.6311e-01, -2.7851e-01,  1.1216e+00, -1.8888e-02],\n",
      "        [ 5.7144e-01, -5.7035e-01, -3.1086e-01,  8.8277e-01, -1.0382e-01],\n",
      "        [ 2.6851e-01, -6.3371e-02, -2.4440e-01,  1.2243e+00,  1.9601e-01],\n",
      "        [ 5.7456e-01, -4.8804e-01, -2.3619e-01,  9.1412e-01, -4.1277e-01],\n",
      "        [-3.2141e-01, -5.2651e-01,  1.1829e-02,  8.4190e-01,  4.4106e-02],\n",
      "        [ 3.6715e-01, -3.5688e-01,  2.4632e-02,  8.5959e-01,  1.7430e-01],\n",
      "        [-1.7392e-01, -1.8324e-01, -2.6287e-02,  6.0086e-01, -8.1701e-03],\n",
      "        [ 4.9886e-01, -5.2799e-02,  7.0207e-02,  5.6758e-01, -3.3193e-01],\n",
      "        [-1.1097e-01, -4.7561e-01,  5.9644e-01,  3.3248e-01,  3.4950e-01],\n",
      "        [ 2.2365e-01,  3.1656e-02, -1.2757e-01,  9.2143e-01,  1.5965e-01],\n",
      "        [-3.1843e-02, -4.7849e-01, -2.7897e-01,  6.9808e-01,  5.6253e-02],\n",
      "        [-1.1894e-01, -2.7142e-01,  5.6112e-01,  7.0765e-01,  3.4295e-01],\n",
      "        [-3.2271e-01, -5.6906e-01,  6.4650e-01,  4.9647e-01,  2.2275e-01],\n",
      "        [-2.9943e-01, -3.3807e-01,  1.0271e-01,  4.8142e-01,  1.3124e-01],\n",
      "        [-8.6634e-02,  6.9368e-02,  2.5695e-01,  9.0408e-01,  2.9342e-01],\n",
      "        [ 4.3555e-01, -2.2336e-01,  3.5263e-01,  9.6040e-01, -1.0648e-01],\n",
      "        [ 1.7996e-01, -2.4276e-01,  1.7380e-01,  1.0268e+00, -1.1280e-01],\n",
      "        [ 2.7893e-01, -5.5595e-01,  4.7218e-01,  2.5828e-01, -3.8255e-02],\n",
      "        [ 2.9157e-01,  1.7832e-01,  2.9333e-01,  3.1188e-01,  4.3268e-01],\n",
      "        [ 9.0095e-02, -1.8541e-01, -2.3045e-01,  1.0946e+00,  5.4142e-01],\n",
      "        [-1.1011e-01, -8.2958e-03,  6.4234e-01,  1.0248e+00, -3.1989e-01],\n",
      "        [ 1.7279e-01, -4.1620e-01,  3.8818e-01,  4.2591e-01,  1.8129e-01],\n",
      "        [ 5.9999e-01, -4.6331e-01,  7.5990e-02,  8.9116e-01,  9.7247e-03],\n",
      "        [-8.3751e-02,  2.1817e-02,  3.7354e-02,  1.1585e+00, -2.5886e-02],\n",
      "        [ 5.3559e-01, -4.6244e-01,  1.1353e-01,  1.0654e+00,  5.3812e-01]],\n",
      "       requires_grad=True) tensor(0.0561)\n",
      "Parameter containing:\n",
      "tensor([[ 2.9729e-01, -6.8368e-02,  7.5866e-01,  5.7129e-01, -1.9068e-01],\n",
      "        [ 5.1918e-01,  6.8833e-01,  7.1459e-01,  1.1653e+00,  8.9814e-01],\n",
      "        [ 6.7608e-01,  7.5427e-01,  2.9217e-01,  7.0939e-02,  6.5721e-01],\n",
      "        [ 7.6672e-01,  4.3128e-01,  2.2724e-01,  1.2307e+00,  9.7575e-01],\n",
      "        [ 2.1700e-01,  3.1175e-01, -6.7062e-04, -2.3679e-02,  6.4770e-01],\n",
      "        [ 3.8887e-01,  6.1058e-01,  8.2644e-01,  4.5256e-01,  3.6083e-01],\n",
      "        [ 1.2396e-01,  7.0635e-01,  5.8811e-01,  5.6014e-01,  2.4747e-01],\n",
      "        [ 8.2260e-01,  7.5858e-01,  1.1202e+00,  9.3261e-01,  4.9916e-01],\n",
      "        [ 7.5708e-01, -1.4377e-01, -7.1480e-02, -2.2004e-01,  2.1730e-01],\n",
      "        [ 9.2115e-01,  8.0534e-01,  5.5063e-01,  1.2111e+00,  4.8708e-01],\n",
      "        [ 7.0478e-01,  6.5488e-01,  7.3548e-01, -2.7329e-01,  4.0630e-01],\n",
      "        [ 4.6083e-01,  5.5831e-01,  1.1378e+00,  8.4468e-01,  3.1199e-01],\n",
      "        [ 6.4473e-01, -9.8815e-02,  4.1301e-01,  6.2433e-01,  9.0466e-02],\n",
      "        [ 1.2018e+00,  5.3005e-01,  1.7986e-01,  5.3559e-01,  3.7128e-01],\n",
      "        [ 1.0454e-02, -1.2885e-01,  2.8521e-01,  3.9357e-02,  6.7658e-01],\n",
      "        [ 8.1081e-01,  2.6111e-01,  8.3778e-01,  1.2706e+00,  1.0666e+00],\n",
      "        [ 2.0567e-01,  3.5417e-01,  2.9181e-02,  1.5403e-02,  6.1081e-01],\n",
      "        [ 3.2735e-01,  4.9542e-01,  4.0104e-01,  7.8674e-01,  1.0812e+00],\n",
      "        [ 2.5056e-01,  1.6188e-01,  8.2551e-01,  5.2690e-01,  2.0026e-01],\n",
      "        [ 1.1777e+00,  8.3650e-01,  7.9594e-01,  1.1034e+00,  3.0651e-01],\n",
      "        [ 2.3655e-01,  7.9433e-02,  7.6374e-01,  5.0837e-01,  5.4445e-01],\n",
      "        [ 1.1229e+00,  8.6626e-01,  2.5166e-01,  1.0279e+00,  3.3827e-01],\n",
      "        [ 3.8039e-02, -1.2139e-01,  2.9241e-01,  2.3471e-01, -4.0092e-02],\n",
      "        [ 4.1829e-01,  4.0753e-01,  2.5476e-01,  1.2207e+00,  2.9957e-01],\n",
      "        [ 3.6146e-01,  1.4752e-01,  6.8416e-01, -2.2652e-01,  2.6606e-01],\n",
      "        [ 1.1422e+00,  8.9829e-01,  1.6849e-01,  5.7277e-01,  6.7734e-01],\n",
      "        [ 7.6331e-01,  7.7905e-01,  3.3990e-01,  4.5990e-01,  3.3222e-01],\n",
      "        [ 8.9986e-01,  5.5824e-01,  7.0541e-01,  1.0160e+00,  8.6639e-01],\n",
      "        [ 1.5568e-01,  7.3674e-01,  4.6876e-01,  1.5320e-02,  3.6797e-01],\n",
      "        [ 3.9018e-01,  9.2534e-01,  9.6321e-01,  1.0043e+00,  1.1709e+00],\n",
      "        [ 7.0706e-01,  6.1348e-01,  1.6465e-01,  5.0182e-01,  5.8770e-01],\n",
      "        [ 9.2541e-01,  1.1322e+00,  3.8284e-01,  5.0404e-01,  1.1578e+00],\n",
      "        [ 6.3575e-01, -7.3125e-03,  5.9411e-01, -8.0856e-02,  4.1759e-01],\n",
      "        [ 1.0784e+00,  1.1040e+00,  4.9793e-01,  1.1835e+00,  4.6962e-01],\n",
      "        [ 7.3222e-01,  4.6734e-01,  6.6800e-01, -1.3471e-01,  6.9644e-01],\n",
      "        [ 1.1660e+00,  7.7761e-01,  8.1970e-01,  9.9837e-01,  2.5409e-01],\n",
      "        [ 2.9507e-01,  4.3125e-01,  2.7371e-01,  6.3090e-01,  4.3218e-01],\n",
      "        [ 9.7381e-01,  1.0985e+00,  7.9400e-01,  1.0769e+00,  6.7830e-01],\n",
      "        [ 5.9422e-01,  5.4224e-01,  5.5748e-02,  2.9886e-01,  1.0447e-01],\n",
      "        [ 1.0962e+00,  6.4259e-01,  6.7459e-01,  8.3114e-01,  2.8028e-01],\n",
      "        [ 7.3984e-01,  1.3865e-01,  4.9714e-01,  4.7009e-01,  6.9184e-01],\n",
      "        [ 2.9765e-01,  5.9798e-01,  4.8899e-01,  6.4910e-01,  7.2567e-01],\n",
      "        [ 6.0465e-01,  6.8421e-01,  1.0393e-01, -2.2537e-01,  8.0762e-02],\n",
      "        [ 1.1682e+00,  9.7260e-01,  4.4074e-01,  1.0862e+00,  8.9352e-01],\n",
      "        [ 4.2952e-01,  4.9762e-01,  5.1243e-01,  2.8043e-01,  1.7030e-01],\n",
      "        [ 7.4321e-01,  6.0248e-01,  8.7341e-01,  4.7715e-01,  6.7387e-01],\n",
      "        [ 1.0642e-01,  4.3319e-01,  7.5614e-01,  3.3470e-01,  2.3340e-01],\n",
      "        [ 2.4300e-01,  7.1100e-01,  6.6782e-01,  1.1959e+00,  5.5090e-01],\n",
      "        [-5.0907e-02,  4.7351e-01,  2.4347e-01, -1.5826e-01,  5.2276e-01],\n",
      "        [ 5.3749e-01,  3.8015e-01,  4.1571e-01,  5.7802e-01,  5.5862e-01],\n",
      "        [ 6.5889e-01, -1.6513e-01, -9.1794e-02, -1.0752e-01,  4.7888e-02],\n",
      "        [ 5.6784e-01,  4.1934e-01,  3.0039e-01,  6.6281e-01,  7.9366e-01],\n",
      "        [ 7.0284e-01,  7.0789e-03, -3.2811e-02, -2.3943e-01, -7.1062e-02],\n",
      "        [ 5.0094e-01,  1.8603e-01,  1.0011e+00,  7.7571e-01,  1.0451e+00],\n",
      "        [ 6.4125e-03,  7.1924e-03,  6.1584e-01,  2.3208e-01, -1.4474e-01],\n",
      "        [ 1.1489e+00,  8.8211e-01,  9.9813e-01,  1.2463e+00,  4.2977e-01],\n",
      "        [-7.5557e-02,  4.2004e-01,  7.2848e-01,  5.6361e-01,  4.8624e-01],\n",
      "        [ 9.6594e-01,  1.0183e-01,  6.0827e-01,  6.9950e-01,  5.4733e-01],\n",
      "        [ 2.4413e-01,  3.0949e-01,  5.8093e-01,  5.1736e-01, -1.6932e-01],\n",
      "        [ 4.9033e-01,  5.1602e-01,  3.1212e-01,  4.0694e-01,  8.9787e-01],\n",
      "        [ 2.0258e-02,  1.0196e-01,  2.8645e-01,  1.9258e-01,  2.4302e-01],\n",
      "        [ 1.0247e+00,  1.6827e-01,  3.4917e-01,  4.9873e-01,  8.1034e-01],\n",
      "        [ 1.4095e-01,  3.9456e-01,  6.0848e-01,  4.1841e-02,  5.9952e-01],\n",
      "        [ 9.6957e-01,  1.2222e-04,  6.4709e-01,  3.5148e-01,  5.9386e-01],\n",
      "        [ 4.6284e-01,  2.2543e-01, -5.3937e-02,  6.0329e-01,  5.6502e-01],\n",
      "        [ 2.5175e-01,  7.7977e-01,  6.2728e-01,  9.6713e-01,  2.9414e-01],\n",
      "        [ 6.0345e-01, -1.6991e-01,  4.4924e-01,  2.6531e-01, -1.3114e-01],\n",
      "        [ 1.0639e+00,  3.5602e-01,  3.6764e-02,  8.7963e-01, -1.6138e-05],\n",
      "        [ 1.9259e-01,  8.7127e-02,  3.6228e-01,  4.0421e-01, -9.7449e-03],\n",
      "        [ 8.9689e-01,  3.6743e-01,  6.2349e-01,  4.2037e-01,  6.1925e-01],\n",
      "        [ 2.9534e-01,  8.9647e-02,  1.4920e-01,  6.9205e-01,  7.2414e-01],\n",
      "        [ 2.6919e-01,  5.1472e-01,  3.9881e-01,  5.1653e-01,  3.7821e-01],\n",
      "        [ 6.7669e-01,  3.9865e-01,  2.5981e-01,  2.9792e-01, -6.1080e-02],\n",
      "        [ 9.2794e-01,  8.7370e-01,  7.2530e-01,  1.0024e+00,  7.7420e-01],\n",
      "        [ 6.0720e-01,  2.5797e-01,  6.0557e-01, -2.6407e-03,  7.6007e-01],\n",
      "        [ 9.9502e-01,  4.4820e-01,  5.3350e-01,  6.2885e-01,  2.7611e-01],\n",
      "        [ 7.7935e-02,  1.4578e-01, -2.3038e-02,  2.7996e-01, -1.0294e-01],\n",
      "        [ 5.1187e-02,  3.3635e-01,  6.0337e-01,  2.8823e-01,  7.8648e-01],\n",
      "        [ 3.9113e-01,  6.9097e-01,  7.2897e-02, -1.5465e-01,  8.0312e-01],\n",
      "        [ 2.5606e-01,  4.1529e-01,  8.5030e-01,  3.5596e-01,  4.9892e-02],\n",
      "        [ 2.2203e-01,  1.1321e-01,  3.7308e-01,  1.1279e-01,  3.7541e-01],\n",
      "        [ 8.5784e-01,  5.1044e-01,  2.3857e-01,  6.7963e-01,  8.0007e-01],\n",
      "        [ 7.6949e-01,  5.6067e-01, -4.5037e-02,  5.8375e-01, -6.6473e-02],\n",
      "        [ 8.6910e-01,  8.2748e-01,  7.1486e-01,  9.0805e-01,  7.7361e-01],\n",
      "        [-1.8989e-01,  5.6638e-01,  7.3954e-01,  5.8168e-01,  1.4319e-02],\n",
      "        [ 6.1511e-01,  5.0316e-01,  3.0090e-01,  5.6343e-01,  7.7211e-01],\n",
      "        [ 5.1794e-01,  2.6640e-01,  2.0166e-01,  8.7963e-02,  4.8752e-01],\n",
      "        [ 6.5513e-01,  9.4791e-02,  5.3660e-01,  8.0423e-02,  6.6816e-02],\n",
      "        [ 6.4228e-01,  7.4499e-02,  5.1170e-01,  5.8216e-01,  1.4884e-01],\n",
      "        [ 7.5851e-01,  3.9330e-01,  7.4518e-01,  4.8454e-01,  8.9236e-01],\n",
      "        [-4.1476e-02,  4.5634e-01,  4.9610e-01,  3.0630e-01,  5.0351e-01],\n",
      "        [ 8.5279e-01,  1.0137e-02, -1.6041e-02,  6.5997e-01,  2.7704e-01],\n",
      "        [-1.8024e-01,  4.7672e-01,  8.3524e-01,  2.6285e-01,  2.5074e-01],\n",
      "        [ 8.8206e-01,  2.0993e-01,  3.2921e-01,  4.5127e-01,  3.5963e-01],\n",
      "        [-5.7231e-02,  1.3455e-01,  6.3642e-01,  6.6924e-01,  7.6503e-01],\n",
      "        [ 5.3744e-01,  4.7986e-01,  8.3126e-01,  8.4800e-01,  5.7399e-01],\n",
      "        [-1.0687e-01,  4.0021e-01,  3.7874e-01,  5.1648e-01,  8.2241e-01],\n",
      "        [ 8.0172e-01,  9.8707e-02,  8.0733e-01,  9.9906e-02,  2.5871e-01],\n",
      "        [ 3.5683e-02,  9.1232e-02, -4.3947e-02,  5.1168e-01,  3.6014e-01],\n",
      "        [ 9.7429e-01,  7.9944e-01,  1.7556e-01,  7.4392e-01,  9.4015e-01],\n",
      "        [-1.1634e-01,  8.8948e-01,  1.9420e-01,  2.9742e-01,  7.5683e-01],\n",
      "        [ 2.2116e-01,  7.1682e-03,  6.9000e-01,  7.5005e-01,  6.1969e-01],\n",
      "        [ 1.0774e-01,  8.1960e-01,  2.3331e-01,  3.2916e-01,  2.3779e-01],\n",
      "        [ 6.8924e-01,  6.9053e-01,  3.8360e-01,  9.8079e-01,  2.3679e-01],\n",
      "        [ 1.2151e-01,  8.7233e-01,  2.2172e-01,  3.1754e-01,  1.5223e-01],\n",
      "        [ 7.7855e-03,  2.8196e-01,  6.1373e-01,  5.5343e-01,  2.5704e-01],\n",
      "        [ 5.5671e-01,  3.3244e-01,  7.7206e-01,  2.5681e-01,  8.6118e-01],\n",
      "        [ 6.6598e-01,  4.3828e-02,  8.5838e-01,  9.1718e-01,  7.1158e-01],\n",
      "        [ 6.9552e-01, -8.4248e-03,  7.6678e-01,  4.2874e-01,  6.3330e-02],\n",
      "        [ 8.9535e-01,  1.2585e-01,  7.3870e-01,  7.5149e-01,  4.9957e-01],\n",
      "        [-1.2126e-01,  6.9864e-01, -2.1839e-02,  1.4204e-01,  7.6712e-02],\n",
      "        [ 6.5757e-01,  8.2981e-01,  4.8595e-01,  6.7868e-01,  6.8503e-01],\n",
      "        [ 7.5048e-01,  1.5416e-03,  5.8289e-01, -2.0067e-01,  7.2884e-01],\n",
      "        [ 5.4093e-01,  3.0940e-01,  3.9416e-01,  3.1847e-02,  3.5774e-01],\n",
      "        [ 5.0920e-01,  9.6418e-01,  3.5648e-01, -1.0398e-01,  6.7394e-01],\n",
      "        [ 9.3889e-01,  8.6317e-01,  3.1056e-01,  8.3402e-01,  1.1965e-02],\n",
      "        [ 6.5531e-01,  5.0615e-01,  2.0069e-01,  5.3098e-01,  2.2840e-01],\n",
      "        [ 1.4043e-01,  7.3019e-01,  9.2302e-01,  6.9688e-01,  2.4427e-02],\n",
      "        [ 1.7343e-01,  5.7570e-01,  8.7759e-01,  8.8058e-02,  4.9964e-01],\n",
      "        [ 6.7123e-01,  8.4671e-01,  5.3267e-01,  4.9226e-01,  2.1466e-02],\n",
      "        [ 2.3992e-02,  3.2447e-01,  8.2024e-01,  4.9626e-01,  1.9802e-01],\n",
      "        [ 2.5700e-01,  5.9900e-01,  9.5395e-01,  1.4351e-01,  9.2079e-01],\n",
      "        [ 4.6817e-01,  3.7201e-01,  4.1545e-01, -6.5592e-02,  3.3672e-01],\n",
      "        [ 5.6333e-01,  1.2105e-01,  7.5068e-01,  5.8574e-01,  3.9809e-02],\n",
      "        [ 1.8855e-01,  1.0028e+00,  1.1050e-01, -2.1664e-01,  4.3262e-01],\n",
      "        [ 8.2065e-01,  5.3340e-02,  7.8573e-01,  4.9943e-01,  8.1567e-01],\n",
      "        [-2.2664e-02,  5.2683e-01,  6.0925e-01,  6.3314e-01,  2.0678e-01],\n",
      "        [ 8.0875e-01,  8.0515e-01,  9.7227e-01,  5.5746e-01,  7.1391e-01]],\n",
      "       requires_grad=True) tensor(0.1322)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1129,  1.3386,  0.7827,  ...,  1.0998,  0.3109,  0.6108],\n",
      "        [ 1.4715,  0.6218,  0.4000,  ...,  0.1703,  0.6358, -0.3449],\n",
      "        [-0.0749,  1.2748,  0.8884,  ...,  1.1803,  1.0159,  1.2020],\n",
      "        ...,\n",
      "        [ 0.5815,  0.5152,  0.2180,  ...,  0.5765,  0.7805,  0.1736],\n",
      "        [ 0.4436,  1.1880,  1.2366,  ...,  0.3093,  1.1909, -0.0468],\n",
      "        [ 0.7699,  1.1318, -0.2095,  ...,  0.8177,  0.4960,  0.1545]],\n",
      "       requires_grad=True) tensor(-2.0955e-09)\n",
      "Parameter containing:\n",
      "tensor([1.5936, 0.6097, 0.4600, 0.8356, 1.4323, 1.5331, 0.6631, 0.4571, 0.5911,\n",
      "        1.5710, 1.4382, 1.5157, 0.5483, 0.6661, 1.5315, 0.5968, 1.2781, 0.4212,\n",
      "        1.1868, 0.5032, 1.4975, 1.1953, 1.5433, 0.7494, 0.9124, 1.1691, 1.2891,\n",
      "        0.8505, 1.2083, 1.5584, 1.3940, 0.4527, 1.5180, 1.5013, 1.4983, 1.1873,\n",
      "        0.8081, 1.5168, 1.2203, 0.6324, 1.4438, 0.9284, 0.7108, 1.5410, 1.4435,\n",
      "        1.1895, 0.4910, 0.6374, 0.4836, 0.6895, 0.8581, 1.5325, 1.2072, 1.5403,\n",
      "        1.4741, 1.5528, 1.4788, 0.6843, 1.4935, 1.1618, 1.3361, 1.1818, 0.6650,\n",
      "        0.8417], requires_grad=True) tensor(-0.0072)\n",
      "Parameter containing:\n",
      "tensor([-0.1892,  0.3015, -0.2751, -0.2256,  0.3515,  0.1889,  0.3984, -0.4011,\n",
      "        -0.3903, -0.2212,  0.4122, -0.3791,  0.4672, -0.1780,  0.3425,  0.4996,\n",
      "        -0.3809, -0.2840,  0.3427, -0.4110, -0.4324,  0.1736, -0.3244,  0.2018,\n",
      "        -0.2374,  0.2281, -0.2177, -0.3589,  0.1875, -0.3299, -0.3156, -0.3960,\n",
      "        -0.1921,  0.1877,  0.2898,  0.4639, -0.4822, -0.4385, -0.2143,  0.5193,\n",
      "        -0.4032,  0.1828,  0.4294,  0.4620, -0.4393, -0.4151,  0.1935, -0.4342,\n",
      "        -0.1667,  0.4415, -0.2083, -0.3513,  0.3632,  0.2849, -0.4087, -0.4716,\n",
      "        -0.4067, -0.2776,  0.4024, -0.1963, -0.3494,  0.1739,  0.3105, -0.4993],\n",
      "       requires_grad=True) tensor(-0.0039)\n",
      "Parameter containing:\n",
      "tensor([[-0.6319, -0.2009,  0.4336,  ...,  0.6483, -0.3117,  0.4899],\n",
      "        [-0.5286,  0.6699,  0.0161,  ...,  0.4857,  0.0577,  0.2851],\n",
      "        [-0.3916,  0.3494, -0.2813,  ..., -0.5051,  0.3716, -0.3338],\n",
      "        ...,\n",
      "        [ 0.4909, -0.3031, -0.4650,  ..., -0.3093,  0.4247, -0.5378],\n",
      "        [ 0.4262, -0.4516, -0.3722,  ..., -0.4515,  0.4339, -0.4261],\n",
      "        [ 0.5847, -0.3814, -0.3348,  ...,  0.1561,  0.2244, -0.5646]],\n",
      "       requires_grad=True) tensor(-0.0034)\n",
      "Parameter containing:\n",
      "tensor([ 0.4994,  0.1265, -0.3199,  0.2238,  0.1915, -0.3500,  0.1642, -0.4406,\n",
      "         0.2316,  0.0870,  0.1104,  0.3838,  0.1489,  0.1660,  0.2670, -0.4543,\n",
      "         0.2889,  0.1906,  0.3558,  0.5249,  0.2822,  0.0685,  0.4713, -0.2075,\n",
      "        -0.2259, -0.1572,  0.4635,  0.5342, -0.1400, -0.1122,  0.0797,  0.4848,\n",
      "        -0.0612,  0.0880, -0.0859, -0.4621,  0.3711, -0.3265,  0.0704, -0.3476,\n",
      "         0.2407,  0.2451,  0.1735,  0.0909,  0.2034,  0.1089,  0.0157, -0.4265,\n",
      "        -0.4886, -0.3441,  0.2810,  0.1049, -0.0820, -0.4757,  0.3835],\n",
      "       requires_grad=True) tensor(0.0004)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.grad.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
